---
# Cluster purge


- name: Stop Ceph services clusterwide (exluding mons)
  hosts: all
  become: true
  tasks:
    - name: Stop Ceph if systemd
      service:
        name: ceph.target
        enabled: no
        state: stopped
      when:
        ansible_service_mgr == "systemd" and "mons" not in group_names


- name: Clear OSDs
  hosts: osds
  become: true
  gather_facts: false

  handlers:
    - name: restart machine
      shell: |
        sleep 2 && shutdown -r now "Ansible updates triggered"
      async: 1
      poll: 0
      ignore_errors: true

    - name: wait for server to boot
      become: false
      local_action: wait_for port=22 host={{ inventory_hostname }} state=started delay=10 timeout=500

    - name: remove data
      file:
        path: /var/lib/ceph
        state: absent

  tasks:
    - set_fact: cluster_data="{{ ansible_local['ceph_%s'|format(cluster)] }}"
    - set_fact: osd_data="{{ cluster_data.osd_tree[ansible_hostname] }}"

    - name: drop all cache
      shell: "sync && sleep 1 && echo 3 > /proc/sys/vm/drop_caches"

    - name: Deactivate OSDs
      command: ceph-disk deactivate --cluster "{{ cluster }}" --deactivate-by-id "{{ item.id }}" --mark-out
      with_items: "{{ osd_data }}"

    - name: Destroy OSDs
      command: ceph-disk destroy --cluster "{{ cluster }}" --destroy-by-id "{{ item.id }}" --zap
      with_items: "{{ osd_data }}"

    - name: is reboot needed
      local_action: shell echo requesting reboot
      become: false
      notify:
        - restart machine
        - wait for server to boot
        - remove data
      when:
        remove_osd_mountpoints.failed is defined


# Please be noticed that monitors should be stopped last
- name: Stop Ceph mongs
  hosts: mons
  become: true
  tasks:
    - name: Stop Ceph if systemd
      service:
        name: ceph.target
        enabled: no
        state: stopped
      when:
        ansible_service_mgr == "systemd"


- name: Remove ceph data
  become: true
  hosts: all
  gather_facts: false
  vars:
    ceph_packages:
      - ceph
      - ceph-common
      - ceph-fs-common
      - ceph-fuse
      - ceph-mds
      - ceph-release
      - ceph-radosgw
    ceph_remaining_packages:
      - libcephfs1
      - librados2
      - libradosstriper1
      - librbd1
      - python-cephfs
      - python-rados
      - python-rbd
  tasks:
    - name: Remove /var/lib/ceph
      file:
        path: /var/lib/ceph
        state: absent

    - name: purge ceph packages with yum
      yum:
        name: "{{ item }}"
        state: absent
      with_items:
        - "{{ ceph_packages }}"
      when:
        ansible_pkg_mgr == 'yum'

    - name: purge ceph packages with dnf
      dnf:
        name: "{{ item }}"
        state: absent
      with_items:
        - "{{ ceph_packages }}"
      when:
        ansible_pkg_mgr == 'dnf'

    - name: purge ceph packages with apt
      apt:
        name: "{{ item }}"
        state: absent
      with_items:
        - "{{ ceph_packages }}"
      when:
        ansible_pkg_mgr == 'apt'

    - name: purge remaining ceph packages with yum
      yum:
        name: "{{ item }}"
        state: absent
      with_items:
        - "{{ ceph_remaining_packages }}"
      when:
        ansible_pkg_mgr == 'yum'

    - name: purge remaining ceph packages with dnf
      dnf:
        name: "{{ item }}"
        state: absent
      with_items:
        - "{{ ceph_remaining_packages }}"
      when:
        ansible_pkg_mgr == 'dnf'

    - name: purge remaining ceph packages with apt
      apt:
        name: "{{ item }}"
        state: absent
      with_items:
        - "{{ ceph_remaining_packages }}"
      when:
        ansible_pkg_mgr == 'apt'

    - name: remove config
      file:
        path: /etc/ceph
        state: absent

    - name: remove from SysV
      shell: "update-rc.d -f ceph remove"
      when:
        ansible_distribution == 'Ubuntu'

    - name: Remove ceph fact
      file:
        path: "/etc/ansible/facts.d/ceph_{{ cluster }}.fact"
        state: absent
