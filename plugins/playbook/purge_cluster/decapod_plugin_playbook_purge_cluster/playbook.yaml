---
# Copyright (c) 2016 Mirantis Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


- name: Stop Ceph services clusterwide (exluding mons)
  hosts: all
  become: true
  tasks:
    - name: Stop Ceph if systemd
      service:
        name: ceph.target
        enabled: no
        state: stopped
      when: ansible_service_mgr == "systemd" and "mons" not in group_names


- name: Stop MDSes
  hosts: mdss
  become: true
  gather_facts: false
  tasks:
    - name: Stop MDS if systemd
      service:
        name: "ceph-mds@{{ ansible_hostname }}"
        state: stopped
        enabled: no


- name: Stop RGWs
  hosts: rgws
  become: true
  gather_facts: false
  tasks:
    - name: Stop RGW if systemd
      service:
        name: "ceph-radosgw@rgw.{{ ansible_hostname }}"
        state: stopped
        enabled: no


- name: Stop RBD Mirrors
  hosts: rbdmirrors
  become: true
  gather_facts: false
  tasks:
    - name: Stop RGW if systemd
      service:
        name: "ceph-rbd-mirror@admin.service"
        state: stopped
        enabled: no


- name: Stop RBD Mirrors
  hosts: nfss
  become: true
  gather_facts: false
  tasks:
    - name: Stop NFS Ganesha if systemd
      service:
        name: nfs-ganesha
        state: stopped
        enabled: no


- name: Clear OSDs
  hosts: osds
  become: true
  gather_facts: false
  tasks:
    - set_fact: cluster_data="{{ ansible_local['ceph_%s'|format(cluster)] }}"
    - set_fact: osd_partitions="{{ cluster_data.osd_partitions[cluster]|default({}) }}"

    - name: test if ceph command exist
      shell: command -v ceph
      changed_when: false
      failed_when: false
      register: ceph_command

    - name: drop all cache
      shell: "sync && sleep 1 && echo 3 > /proc/sys/vm/drop_caches"

    - block:
        - set_fact: mon_host="{{ groups['mons'].0 }}"

        - name: Get OSD numbers from monitor
          command: ceph --cluster "{{ cluster }}" node ls osd
          register: node_ls_osd
          delegate_to: "{{ mon_host }}"

        - set_fact: osd_numbers="{{ (node_ls_osd.stdout|trim|from_json)[ansible_nodename]|default([]) }}"

        - name: Decrease weight of removing OSDs
          command: ceph --cluster "{{ cluster }}" osd crush reweight "osd.{{ item }}" 0.0
          with_items: "{{ osd_numbers }}"
          delegate_to: "{{ mon_host }}"

        - name: Set OSDs out of cluster
          command: ceph --cluster "{{ cluster }}" osd out "{{ item }}"
          with_items: "{{ osd_numbers }}"
          delegate_to: "{{ mon_host }}"

        # At this step we have to wait till cluster will rebalance
        # TODO(Sergey Arkhipov): Probably it has to be implemented as ansible module

        # For some reason, jewel ceph-disk does not stop daemon on
        # ceph-disk deactivate. It also does not umount /var/lib/ceph/osd-*
        # mount point, therefore we have to make sunset manually.

        - name: Stop OSDs on Ubuntu before Xenial
          command: initctl stop ceph-osd cluster={{ cluster }} id={{ item }}
          with_items: "{{ osd_numbers }}"
          when: ansible_distribution == "Ubuntu" and ansible_distribution_major_version == "14"

        - name: Stop OSDs on Ubuntu after Xenial
          command: systemctl stop "ceph-osd@{{ item }}"
          with_items: "{{ osd_numbers }}"
          when: ansible_distribution == "Ubuntu" and ansible_distribution_major_version != "14"

        - name: Get OSD mount points
          shell: "(grep /var/lib/ceph/osd /proc/mounts || echo -n) | awk '{ print $2 }'"
          register: mounted_osd
          changed_when: false

        - name: Unmount OSD mount points
          command: umount "{{ item }}"
          with_items: "{{ mounted_osd.stdout_lines }}"

        - name: Set OSDs down
          command: ceph --cluster "{{ cluster }}" osd down "{{ item }}"
          with_items: "{{ osd_numbers }}"
          delegate_to: "{{ mon_host }}"

        - name: Remove OSDs from crush map
          command: ceph --cluster "{{ cluster }}" osd crush remove "osd.{{ item }}"
          with_items: "{{ osd_numbers }}"
          delegate_to: "{{ mon_host }}"

        - name: Delete auth data for OSDs
          command: ceph --cluster "{{ cluster }}" auth del "osd.{{ item }}"
          with_items: "{{ osd_numbers }}"
          delegate_to: "{{ mon_host }}"

        - name: Remove OSDs
          command: ceph --cluster "{{ cluster }}" osd rm "osd.{{ item }}"
          with_items: "{{ osd_numbers }}"
          delegate_to: "{{ mon_host }}"
      when: groups["mons"] is defined and groups["mons"] and ceph_command.rc == 0

    # Another caveat you may meet. It looks great to use ceph-disk destroy
    # but there is a lot of cases when it fails. For example, if dmcrypt
    # exists, you need to have keys (but, well, you need to destroy partition,
    # right?). Or it may hangs for unknown reason.
    #
    # So again, sunset manually.
    - name: Destroy OSD data partitions
      shell: |
        raw_device=$(echo "{{ item.value.data }}" | egrep -o '/dev/([hsv]d[a-z]{1,2}|cciss/c[0-9]d[0-9]p|nvme[0-9]n[0-9]p){1,2}')
        partition_nb=$(echo "{{ item.value.data }}" | egrep -o '[0-9]{1,2}$')
        sgdisk --delete $partition_nb $raw_device
      with_dict: "{{ osd_partitions }}"

    - name: Destroy OSD journal partitions
      shell: |
        raw_device=$(echo "{{ item.value.journal }}" | egrep -o '/dev/([hsv]d[a-z]{1,2}|cciss/c[0-9]d[0-9]p|nvme[0-9]n[0-9]p){1,2}')
        partition_nb=$(echo "{{ item.value.journal }}" | egrep -o '[0-9]{1,2}$')
        sgdisk --delete $partition_nb $raw_device
      with_dict: "{{ osd_partitions }}"


# Please be noticed that monitors should be stopped last
- name: Stop Ceph mons
  hosts: mons
  become: true
  tasks:
    - name: Stop Ceph if systemd
      service:
        name: ceph.target
        enabled: no
        state: stopped
      when: ansible_service_mgr == "systemd"


- name: Remove ceph data
  become: true
  hosts: all
  gather_facts: false
  vars:
    ceph_packages:
      - ceph
      - ceph-common
      - ceph-fs-common
      - ceph-fuse
      - ceph-mds
      - ceph-release
      - ceph-radosgw
    ceph_remaining_packages:
      - libcephfs1
      - librados2
      - libradosstriper1
      - librbd1
      - python-cephfs
      - python-rados
      - python-rbd
  tasks:
    - name: Remove /var/lib/ceph
      file:
        path: /var/lib/ceph
        state: absent

    - name: purge ceph packages with yum
      yum:
        name: "{{ item }}"
        state: absent
      with_items: "{{ ceph_packages }}"
      when: ansible_pkg_mgr == "yum"

    - name: purge ceph packages with dnf
      dnf:
        name: "{{ item }}"
        state: absent
      with_items: "{{ ceph_packages }}"
      when: ansible_pkg_mgr == "dnf"

    - name: purge ceph packages with apt
      apt:
        name: "{{ item }}"
        state: absent
      with_items: "{{ ceph_packages }}"
      when: ansible_pkg_mgr == "apt"

    - name: purge remaining ceph packages with yum
      yum:
        name: "{{ item }}"
        state: absent
      with_items: "{{ ceph_remaining_packages }}"
      when: ansible_pkg_mgr == "yum"

    - name: purge remaining ceph packages with dnf
      dnf:
        name: "{{ item }}"
        state: absent
      with_items: "{{ ceph_remaining_packages }}"
      when: ansible_pkg_mgr == "dnf"

    - name: purge remaining ceph packages with apt
      apt:
        name: "{{ item }}"
        state: absent
      with_items: "{{ ceph_remaining_packages }}"
      when: ansible_pkg_mgr == "apt"

    - name: remove config
      file:
        path: /etc/ceph
        state: absent

    - name: remove from SysV
      command: "update-rc.d -f ceph remove"
      when: ansible_distribution == "Ubuntu"

    - name: Remove ceph fact
      file:
        path: "/etc/ansible/facts.d/ceph_{{ cluster }}.fact"
        state: absent
